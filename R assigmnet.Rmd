---
title: "hw1"
author: "yajur sehra"
date: "2023-08-16"
output: html_document
---


```{r} 
getwd()
library(tidyverse)
library(ggplot2)
library(dplyr)
 # question 1 
#reading dataset

hwq1 <- read.csv("Dow.csv")
head(hwq1)
str(hwq1)
#q1 part a
#converting closing values chr to num
hwq1$Closing.Values <- as.numeric(gsub(",", "", hwq1$Closing.Values))

#calculating daily return percent
hwq1 <- hwq1 %>% 
  mutate(daily_returns = ((Closing.Values - lag(Closing.Values))*100)/lag(Closing.Values))
str(hwq1)

average_return <- mean(hwq1$daily_returns, na.rm = TRUE)
cat("Average Dow Return:", average_return,"percent")

#q1 part b
ggplot(hwq1, aes(x = daily_returns)) +
  geom_histogram(binwidth = 0.5, fill = "yellow", color = "black") +
  labs(title = "Histogram of Daily Returns",
       x = "Daily Return",
       y = "Frequencies")
sprintf("The histogram of daily returns is almost bell shaped, i.e., normally distributed, most of the data values are near 0.")

#q1 partc

stddev <- sd(hwq1$daily_returns, na.rm = TRUE)

sprintf("The std dev of daily returns is %.4f.", stddev)

TotalSampleSize <- length(hwq1$daily_returns)

# One std dev bounds
One_SD_Range_Lower <- average_return - 1*stddev
One_SD_Range_Upper <- average_return + 1*stddev

# observations within 1 SD (around 68%) 
Num_Within_One_SD <- length(which(hwq1$daily_returns >= One_SD_Range_Lower & hwq1$daily_returns <= One_SD_Range_Upper))
Percent_Within_One_SD <- 100*(Num_Within_One_SD/TotalSampleSize)

# Two std dev bounds
Two_SD_Range_Lower <- average_return - 2*stddev
Two_SD_Range_Upper <- average_return + 2*stddev

# observations within 2 SD (around 95%) 
Num_Within_Two_SD <- length(which(hwq1$daily_returns >= Two_SD_Range_Lower & hwq1$daily_returns <= Two_SD_Range_Upper))
Percent_Within_Two_SD <- 100*(Num_Within_Two_SD/TotalSampleSize)

# Three std dev bounds
Three_SD_Range_Lower <- average_return - 3*stddev
Three_SD_Range_Upper <- average_return + 3*stddev

# observations within 2 SD (around 99.7%) 
Num_Within_Three_SD <- length(which(hwq1$daily_returns >= Three_SD_Range_Lower & hwq1$daily_returns <= Three_SD_Range_Upper))
Percent_Within_Three_SD <- 100*(Num_Within_Three_SD/TotalSampleSize)

sprintf("%.1f%% of the Returns are within 1SD from the mean.", Percent_Within_One_SD)
sprintf("%.1f%% of the Returns are within 2SD from the mean.", Percent_Within_Two_SD)
sprintf("%.1f%% of the Returns are within 3SD from the mean.", Percent_Within_Three_SD)

#q1 part d

ggplot(hwq1, aes(x = daily_returns)) +
  geom_boxplot(fill = "lightgreen", color = "black") +
  labs(title = "Boxplot of Daily Returns",
       x = "Daily Return") 

five_number_summary <- summary(hwq1$daily_returns, quantiles = c(0.25, 0.5, 0.75))
cat("Five-Number Summary:\n")
cat("Minimum:", min(hwq1$daily_returns, na.rm = TRUE), "\n")
cat("1st Quartile (Q1):", five_number_summary[2], "\n")
cat("Median (Q2):", five_number_summary[3], "\n")
cat("3rd Quartile (Q3):", five_number_summary[4], "\n")
cat("Maximum:", max(hwq1$daily_returns, na.rm = TRUE), "\n")
sprintf("First Quartile: 25 percent of Daily returns are less than %.2f percent and 75 percent of them are more than %.2f percent .", five_number_summary[2], five_number_summary[2])

sprintf("Second Quartile: 50 percent of Daily returns are less than %.2f percent and 50 percent of them are more than %.2f percent .", five_number_summary[3], five_number_summary[3])

sprintf("Third Quartile: 75 percent of Daily returns are less than %.2f percent and 25 percent of them are more than %.2f percent.", five_number_summary[4], five_number_summary[4])

#q1 part e
q1 <- quantile(hwq1$daily_returns, 0.25, na.rm = TRUE)
q3 <- quantile(hwq1$daily_returns, 0.75, na.rm = TRUE)

# Calculate the IQR
iqr <- IQR(hwq1$daily_returns, na.rm = TRUE)

# Define thresholds for mild and extreme outliers
mild_outlier_threshold <- 1.5 * iqr
extreme_outlier_threshold <- 3 * iqr

# Classify each monthly return
hwq1 <- hwq1 %>%
  mutate(Outlier_Status = case_when(
    daily_returns < (q1 - extreme_outlier_threshold) ~ "Extreme Outlier",
    daily_returns > (q3 + extreme_outlier_threshold) ~ "Extreme Outlier",
    daily_returns < (q1 - mild_outlier_threshold) ~ "Mild Outlier",
    daily_returns > (q3 + mild_outlier_threshold) ~ "Mild Outlier",
    TRUE ~ "Not an Outlier"
  ))

# Sort and display the results
sorted_data <- hwq1 %>%
  arrange(Outlier_Status)

# Print the sorted results
print(sorted_data)

#
### q2 ###
#

#q2 part a

hwq2 <- read.csv("MutualFunds.csv")
head(hwq2)

ggplot(hwq2, aes(y = "Mutual Fund 1", x = MF1)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(title = "Boxplot of Mutual Fund 1 Returns",
       y = "Mutual Fund",
       x = "Returns (%)")
sprintf("Two bubbles on the right suggests outliers")

#q2 part b
mutual_fund_1_returns <- hwq2$MF1
z_scores <- (mutual_fund_1_returns - mean(mutual_fund_1_returns)) / sd(mutual_fund_1_returns)

# Define a threshold for outliers 
outlier_threshold <- 2

outliers <- abs(z_scores) > outlier_threshold
# Identify outliers
num_outliers <- sum(outliers)

# Print the number of outliers
cat("Number of Mutual Fund 1 outliers:", num_outliers, "\n")
# Display the outliers
outlier_indices <- which(outliers)
outlier_values <- mutual_fund_1_returns[outlier_indices]

# Print the indices and values of outliers
cat("Indices of Mutual Fund 1 outliers:", outlier_indices, "\n")
cat("Values of Mutual Fund 1 outliers:", outlier_values, "\n")

sprintf("Results differ in Boxplot and Z-Score, Boxplots uses a rule of thumb to define outliers based on how far data points are from the quartiles and the IQR. If the data distribution is skewed or has long tails, a boxplot might label some data points as outliers that wouldn't be identified as such by z-scores, one extreme outlier is identified by z-score but not the other one. Also a smaller sample size like this can affect the result of z-score because 1 observation holds higher impact")

#q2 part c

ggplot(hwq2, aes(y = "Mutual Fund 2", x = MF2)) +
  geom_boxplot(fill = "lightyellow", color = "black") +
  labs(title = "Boxplot of Mutual Fund 2 Returns",
       y = "Mutual Fund",
       x = "Returns (%)")
sprintf("One bubble on the extreme left suggests outliers")

#q2 part d
mutual_fund_2_returns <- hwq2$MF2
z_scores_2 <- (mutual_fund_2_returns - mean(mutual_fund_2_returns)) / sd(mutual_fund_2_returns)

# Define a threshold for outliers
outlier_threshold_2 <- 2
outliers_2 <- abs(z_scores_2) > outlier_threshold_2
# Identify outliers
num_outliers_2 <- sum(outliers_2)

# Print the number of outliers
cat("Number of Mutual Fund 2 outliers:", num_outliers_2, "\n")
# Display the outliers
outlier_indices_2 <- which(outliers_2)
outlier_values_2 <- mutual_fund_2_returns[outlier_indices_2]

# Print the indices and values of outliers
cat("Indices of Mutual Fund 2 outliers:", outlier_indices_2, "\n")
cat("Values of Mutual Fund 2 outliers:", outlier_values_2, "\n")

sprintf("Results are same in Boxplot and Z-Score as its an extreme outlier and fits the definition of both boxplot and zscore outliers")


##question 3

hwq3 <- read.csv("MetroHomes.csv")
head(hwq3)
str(hwq3)

ggplot(hwq3, aes(y = Crime.Rate, x = Selling.Price)) +
  geom_point() +
  labs(title = "Scatterplot of Selling Price vs. Crime Rate",
       y = "Crime Rate",
       x = "Selling Price")
sprintf("According to the observation, 1 value stands out with an extremely high crime rate which seems to be an outlier")

correlation_1 <- cor(hwq3$Crime.Rate, hwq3$Selling.Price)
cat("Correlation between Crime Rate and Selling Price:", correlation_1, "\n")

z_scores_Selling_Price <- (hwq3$Selling.Price - mean(hwq3$Selling.Price)) / sd(hwq3$Selling.Price)
z_scores_Crime_Rate <- (hwq3$Crime.Rate - mean(hwq3$Crime.Rate)) / sd(hwq3$Crime.Rate)

# Define a z-score threshold for outliers
z_score_threshold <- 2  # Adjust this value as needed

# Identify outlier indices
outlier_indices <- which(abs(z_scores_Selling_Price) > z_score_threshold | abs(z_scores_Crime_Rate) > z_score_threshold)

# Remove outliers
data_cleaned <- hwq3[-outlier_indices, ]

ggplot(data_cleaned, aes(y = Crime.Rate, x = Selling.Price)) +
  geom_point() +
  labs(title = "Scatterplot of Selling Price vs. Crime Rate",
       y = "Crime Rate",
       x = "Selling Price")

correlation <- cor(data_cleaned$Crime.Rate, data_cleaned$Selling.Price)
cat("Correlation between Crime Rate and Selling Price:", correlation, "\n")
sprintf("After removing the outlier, the correlation almost doubled, making both factors highly related")

#ques6
#q6 part a
cost_replace <- 7500
cost_per_call <- 500
budget <- 2000
prob_fix <- 0.27

# Define a function to calculate the cost of a certain number of repair visits
find_cost <- function(visits) {
  total_cost <- cost_replace + cost_per_call * visits
  if (total_cost > budget) {
    return(budget)
  }
  return(total_cost)
}

# Create a vector of possible visits (trials)
visits <- 0:50

# Calculate the probabilities for each number of visits
probabilities <- dnbinom(visits, size = 1, prob = prob_fix)

# Calculate the cumulative probabilities
cumulative_probabilities <- cumsum(probabilities)

data <- data.frame(visits = visits, probability = probabilities, cumulative_probability = cumulative_probabilities)
 print(data)

#q6 part b
expected_visits <- sum(visits * probabilities)
cat("Expected number of service technicians:", expected_visits, "\n")

#q6 part c
expected_amount_spent <- sum(visits * cost_per_call * probabilities) + cost_replace * (1 - prob_fix)


cat("Expected amount spent on repairs:", expected_amount_spent, "\n")

sprintf("Amount to repair is less than replacing")


#ques 8

# Define the function to calculate the acceptance probability
acceptance_probability <- function(p_defective) {
  q <- 1 - p_defective
  p_accept <- sum(dbinom(0:4, size = 50, prob = p_defective))
  return(p_accept)
}

# Define the range of defective fractions
defective_fractions <- c(0.02, 0.04, 0.06, 0.08, 0.10, 0.12, 0.14, 0.16, 0.18)

# Calculate acceptance probabilities for each defective fraction
acceptance_probabilities <- sapply(defective_fractions, acceptance_probability)

# Create a bar plot
barplot(acceptance_probabilities, names.arg = defective_fractions,
        xlab = "Defective Fraction", ylab = "Acceptance Probability",
        main = "Acceptance Probability vs. Defective Fraction")

# Print the calculated acceptance probabilities
cat("Defective Fractions:", defective_fractions, "\n")
cat("Acceptance Probabilities:", acceptance_probabilities, "\n")

# Revised acceptance probability function
revised_acceptance_probability <- function(p_defective) {
  q <- 1 - p_defective
  p_accept <- sum(dbinom(0:5, size = 50, prob = p_defective))
  return(p_accept)
}

# Calculate acceptance probabilities for each defective fraction (revised plan)
revised_acceptance_probabilities <- sapply(defective_fractions, revised_acceptance_probability)

# Create a bar plot for the revised plan
barplot(revised_acceptance_probabilities, names.arg = defective_fractions,
        xlab = "Defective Fraction", ylab = "Acceptance Probability",
        main = "Revised Acceptance Probability vs. Defective Fraction")

# Print the calculated acceptance probabilities (revised plan)
cat("Revised Acceptance Probabilities:", revised_acceptance_probabilities, "\n")

#ques 9

#q9 part a

fixed_cost <- 1000
cost_plain_cheese <- 4.50
cost_veggie_cheese <- 5.00
selling_price <- 9.00

demand_plain_cheese <- c(200, 300, 400, 500, 600, 700, 800, 800)
prob_plain_cheese <- c(0.10, 0.15, 0.10, 0.20, 0.20, 0.10, 0.05, 0.05)

demand_veggie_cheese <- c(300, 400, 500, 600, 700, 800)
prob_veggie_cheese <- c(0.10, 0.20, 0.25, 0.25, 0.15, 0.05)

# Create empty data frames to store results
result_plain_cheese <- data.frame(demand = demand_plain_cheese)
result_veggie_cheese <- data.frame(demand = demand_veggie_cheese)

# Calculate profit for plain cheese pizzas
for (production in demand_plain_cheese) {
  profit <- (min(production, demand_plain_cheese) * selling_price) - 
            ((production * cost_plain_cheese) + (fixed_cost / 2))
  result_plain_cheese[, as.character(production)] <- profit * prob_plain_cheese
}

# Calculate profit for veggie-and-cheese combo pizzas
for (production in demand_veggie_cheese) {
  profit <- (min(production, demand_veggie_cheese) * selling_price) - 
            ((production * cost_veggie_cheese) + (fixed_cost / 2))
  result_veggie_cheese[, as.character(production)] <- profit * prob_veggie_cheese
}

# Print the two-way data tables
print("Plain Cheese Pizza Profit Table:")
print(result_plain_cheese)

print("Veggie-and-Cheese Combo Pizza Profit Table:")
print(result_veggie_cheese)

#q9 part b



# Calculate expected profit for plain cheese pizzas
expected_profit_plain_cheese <- numeric(length(demand_plain_cheese))

for (i in seq_along(demand_plain_cheese)) {
  production <- demand_plain_cheese[i]
  profit <- (min(production, demand_plain_cheese) * selling_price) -
            ((production * cost_plain_cheese) + (fixed_cost / 2))
  expected_profit_plain_cheese[i] <- sum(profit * prob_plain_cheese)
}

# Calculate expected profit for veggie-and-cheese combo pizzas
expected_profit_veggie_cheese <- numeric(length(demand_veggie_cheese))

for (i in seq_along(demand_veggie_cheese)) {
  production <- demand_veggie_cheese[i]
  profit <- (min(production, demand_veggie_cheese) * selling_price) -
            ((production * cost_veggie_cheese) + (fixed_cost / 2))
  expected_profit_veggie_cheese[i] <- sum(profit * prob_veggie_cheese)
}

# Print the vectors of expected profits
print("Expected Profit Vector for Plain Cheese Pizza:")
print(expected_profit_plain_cheese)

print("Expected Profit Vector for Veggie-and-Cheese Combo Pizza:")
print(expected_profit_veggie_cheese)

#q9 partc

max_expected_profit_plain_cheese <- which.max(expected_profit_plain_cheese)
max_expected_profit_veggie_cheese <- which.max(expected_profit_veggie_cheese)

# Determine the corresponding production levels that maximize the expected profit
production_plain_cheese <- demand_plain_cheese[max_expected_profit_plain_cheese]
production_veggie_cheese <- demand_veggie_cheese[max_expected_profit_veggie_cheese]

# Print the results
print("To maximize expected profit:")
cat("Produce", production_plain_cheese, "Plain Cheese Pizzas\n")
cat("Produce", production_veggie_cheese, "Veggie-and-Cheese Combo Pizzas\n")

# Ques 7
#q7 part a

# Probability of purchasing membership
prob_purchase <- 0.4

#attendees
attendees <- 20

#attendees who will purchase
attendees_purchase <- 10

#probability using dbinom
probability <- dbinom(attendees_purchase, size = attendees, prob = prob_purchase)

# Printing the result
print(probability)

#q7 part b

prob_purchase <- 0.4

#attendees
attendees <- 20

#cumulative probability using pbinom for no more than 10 attendees
cumulative_probability <- pbinom(10, size = attendees, prob = prob_purchase)

print(cumulative_probability)

#q7 part c

prob_purchase <- 0.4

attendees <- 20

#cumulative probability for 14 or fewer attendees not purchasing using pbinom
cumulative_prob_less_than_15 <- pbinom(14, size = attendees, prob = prob_purchase)

# Calculating the prob of at least 15 attendees purchasing
prob_at_least_15 <- 1 - cumulative_prob_less_than_15

print(prob_at_least_15)

#ques 10

#q10 part a

initial_investment <- 6000
interest_a <- 0.12
interest_b <- 0.24
prob_same <- 0.6
prob_soar <- 0.4
exchange_rate <- 16

#future values
future_val_a <- initial_investment * (1 + interest_a)
future_val_b <- (initial_investment * exchange_rate)* (1 + interest_b) 

#expected values
expected_val_a <- prob_same * future_val_a
expected_val_b <- prob_soar * future_val_b

#  conclusion
if (expected_val_b > expected_val_a) {
  conclusion <- "Investment in B has a high expected value."
} else if (expected_val_a > expected_val_b) {
  conclusion <- "Investment in A has a high expected value."
} else {
  conclusion <- "Same expected value for both A and B investments."
}

#results
cat("Expected Value of A:", expected_val_a, "\n")
cat("Expected Value of B:", expected_val_b, "\n")
cat(conclusion)


##q10 part b


#1- Convert pesos to dollars

initial_pesos <- 96000
exchange_rate_a <- 1 / 16
interest_rate_a <- 0.12

future_val_opt1 <- initial_pesos * exchange_rate_a * (1 + interest_rate_a)
expected_val_opt1 <- future_val_opt1

#2- Invest locally in B
interest_rate_b <- 0.24

future_val_opt2 <- initial_pesos * (1 + interest_rate_b)
expected_val_opt2 <- future_val_opt2


if (expected_val_opt1 > expected_val_opt2) {
  result <- "Option 1 is better."
} else if (expected_val_opt2 > expected_val_opt1) {
  result <- "Option 2 is better."
} else {
  result <- "Same expected value for both options."
}

print(result)

#q10 part c

initial_pesos <- 96000
same_exchange_rate <- 16
soar_exchange_rate <- 32
same_prob <- 0.6
soar_prob <- 0.4
interest_rate_a <- 0.12
interest_rate_b <- 0.24

#future values
stable_future_val_1 <- initial_pesos / same_exchange_rate * (1 + interest_rate_a)
soar_future_val_1 <- initial_pesos / soar_exchange_rate * (1 + interest_rate_a)
future_val_2 <- initial_pesos * (1 + interest_rate_b)

#expected values
expected_val1 = same_prob * stable_future_val_1 + soar_prob * soar_future_val_1
expected_val2 = future_val_2

# Compare
if (expected_val1 > expected_val2) {
  print("Option 1 has a higher expected value.")
} else if (expected_val1 < expected_val2) {
  print("Option 2 has a higher expected value.")
} else {
  print("Same expected value for both options.")
}

#ques 4
options(repos = c(CRAN = "https://cran.rstudio.com/"))
install.packages("corrplot")
install.packages("gridExtra")

library(dplyr)
library(ggplot2)
library(corrplot)
library(gridExtra)

# Load data from CSV file
hwq4 <- read.csv("CellphoneMarket.csv")
head(hwq4)


# Columns B to R
eda_columns <- c("Account.Length", "Voice.Mail.Messages", "Day.Minutes", "Day.Calls", "Day.Charge",
                 "Evening.Minutes", "Evening.Calls", "Evening.Charge", "Night.Minutes",
                 "Night.Calls", "Night.Charge", "International.Minutes", "International.Calls",
                 "International.Charge", "Customer.Service.Calls")

# EDA: Histograms for numeric variables
numeric_data <- hwq4 %>%
  select(all_of(eda_columns)) %>%
  gather(key = "variable", value = "value") %>%
  ggplot(aes(x = value)) +
  geom_histogram(bins = 20) +
  facet_wrap(~ variable, scales = "free_x") +
  labs(title = "Distribution of Numeric Variables")

# EDA: Bar plots for categorical variables
categorical_data <- hwq4 %>%
  select("International.Plan", "Voice.Mail.Plan", "Churn") %>%
  gather(key = "variable", value = "value") %>%
  group_by(variable, value) %>%
  summarise(count = n()) %>%
  ggplot(aes(x = reorder(value, -count), y = count, fill = value)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ variable, scales = "free_x") +
  labs(title = "Distribution of Categorical Variables")

# Combine and display EDA plots
grid.arrange(numeric_data, categorical_data, ncol = 1)



# Create a correlation heatmap with axis labels
correlation_matrix <- cor(hwq4[, c("Account.Length", "Voice.Mail.Messages", "Day.Minutes", "Day.Calls", "Day.Charge",
                                   "Evening.Minutes", "Evening.Calls", "Evening.Charge", "Night.Minutes", "Night.Calls",
                                   "Night.Charge", "International.Minutes", "International.Calls", "International.Charge",
                                   "Customer.Service.Calls")])

corrplot(correlation_matrix, method = "color", 
         tl.col = "black", tl.srt = 45,
         diag = FALSE)

variable_names <- c("Account.Length", "Voice.Mail.Messages", "Day.Minutes", "Day.Calls", "Day.Charge",
                    "Evening.Minutes", "Evening.Calls", "Evening.Charge", "Night.Minutes",
                    "Night.Calls", "Night.Charge", "International.Minutes", "International.Calls",
                    "International.Charge", "Customer.Service.Calls")


z_score_results <- lapply(variable_names, function(var) {
  z_scores_yes <- scale(hwq4[data$Churn == "Yes", var])
  z_scores_no <- scale(hwq4[data$Churn == "No", var])
  list(Variable = var,
       churns_yes = mean(z_scores_yes),
       churns_no = mean(z_scores_no))
})

# Create a data frame of z-score results
z_score_df <- do.call(rbind.data.frame, z_score_results)

#results
print(z_score_df)

sprintf("Columns with significant Z-score  are related to churning, account length and evening charge should be handeled carefully ")


#ques 5

expansion <- data.frame(
  sales = c("high", "moderate", "low"),
  probability = c(0.5, 0.25, 0.25),
  cash_flow = c(100, 75, 40),
  initial_cost = 60,
  NPV = c(40, 15, -20)
)

enter_new_market <- data.frame(
  sales = c("high", "moderate", "low"),
  probability = c(0.2, 0.5, 0.3),
  cash_flow = c(200, 75, 25),
  initial_cost = 60,
  NPV = c(140, 15, -35)
)

# Calculate expected NPV for expansion project
expansion_expected_NPV <- sum(expansion$probability * expansion$NPV)

# Calculate variance and standard deviation of NPV for expansion project
expansion_variance <- sum(expansion$probability * (expansion$NPV - expansion_expected_NPV)^2)
expansion_std_dev <- sqrt(expansion_variance)

# Calculate expected NPV for entering new market project
enter_new_market_expected_NPV <- sum(enter_new_market$probability * enter_new_market$NPV)

# Calculate variance and standard deviation of NPV for entering new market project
enter_new_market_variance <- sum(enter_new_market$probability * (enter_new_market$NPV - enter_new_market_expected_NPV)^2)
enter_new_market_std_dev <- sqrt(enter_new_market_variance)

# Print the results
cat("Expected NPV for Expansion Project:", expansion_expected_NPV, "\n")
cat("Variance of NPV for Expansion Project:", expansion_variance, "\n")
cat("Standard Deviation of NPV for Expansion Project:", expansion_std_dev, "\n\n")

cat("Expected NPV for Entering New Market Project:", enter_new_market_expected_NPV, "\n")
cat("Variance of NPV for Entering New Market Project:", enter_new_market_variance, "\n")
cat("Standard Deviation of NPV for Entering New Market Project:", enter_new_market_std_dev, "\n\n")

# Determine which project has the higher expected NPV
if (expansion_expected_NPV > enter_new_market_expected_NPV) {
  cat("Expansion Project has the higher expected NPV.\n")
} else {
  cat("Entering New Market Project has the higher expected NPV.\n")
}


```








